{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# EDGAR handler\n",
      "this application manages the interaction between Nucleus DB and the EDGAR FTP source. \n",
      "\n",
      "## EDGAR MAP\n",
      "\n",
      "\n",
      "What is needed? \n",
      "### Map\n",
      "\n",
      "1. An app that builds the initial masters db. \n",
      "2. An app that updates the map  on a daily basis. \n",
      "### Files\n",
      "\n",
      "3. An app that looks up a CIK given a ticker name\n",
      "    - updates the map\n",
      "    - \n",
      "    - checks local DB against map to get only the missing files\n",
      "    - Allows filtering by: \n",
      "        - CIK \n",
      "        - start_day\n",
      "        - end_day\n",
      "        - form type\n",
      "    - Scrapes information from the Forms. \n",
      "        - \n",
      "    - uploads information to the DB. \n",
      "    \n",
      "\n",
      " # International equivalents of EDGAR\n",
      " \n",
      "## Canada \n",
      "http://www.sedar.com/search/search_en.htm\n",
      " \n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Problem: the EDGAR masters take way too long to download. We cannot DL it everytime the DB starts. \n",
      "we need a process that: \n",
      "\n",
      "\n",
      "A. Update files Mechanism: \n",
      "\n",
      "if last date is more than 2 months old: \n",
      "\n",
      "1. checks what's the last day\n",
      "2. get the monthly file for the last day's month. \n",
      "3. compare the list on the file against the DB. \n",
      "    query for all the records that are in the last day's month\n",
      "4. upload the data. \n",
      "5. get monthly files until you find the end of quater. \n",
      "6. once you reach end of quater get the quaterly files and keep moving fwd. \n",
      "\n",
      "   - First quarter: from the beginning of January to the end of March\n",
      "   - Second quarter: from the beginning of April to the end of June\n",
      "   - Third quarter: from the beginning of July to the end of September\n",
      "   - Fourth quarter: from the beginning of October to the end of December\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### ----------------------------------------------------------------------\n",
      "# Change in plans... \n",
      "### ----------------------------------------------------------------------\n",
      "\n",
      "I added the CIK to the ticker table. \n",
      "to use these changes: \n",
      "\n",
      "1. build a foreign key in the edgar_map table, use cpy_id instead of cik\n",
      "2. add industry information from edgar. \n",
      "3. this allows for easy mapping of the edgar industry codes to companies. \n",
      "4. get_cik becomes a simple db query. \n",
      "5. tables built for filings will use cpy_id foreign key. \n",
      "6. \n",
      "\n",
      "# YAHOO is useless. \n",
      "SEC website can handle ticker\n",
      "\n",
      "http://www.sec.gov/cgi-bin/browse-edgar?CIK=XOM&Find=Search&owner=exclude&action=getcompany"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "CREATE TABLE IF NOT EXISTS edgar_map -- this table holds the index that describes the EDGAR FTP site\n",
      "(\n",
      "    edgar_id SERIAL NOT NULL,\n",
      "    edgar_timestamp TIMESTAMP NOT NULL,\n",
      "    edgar_cik INT NOT NULL,  \n",
      "    form_type VARCHAR(20),\n",
      "    edgar_name VARCHAR(200) NOT NULL,\n",
      "    edgar_filename VARCHAR(200) NOT NULL,\n",
      "    primary key (edgar_id)\n",
      "); \n",
      "CREATE INDEX edgar_cik_idx ON edgar_map(edgar_cik);\n",
      "CREATE INDEX edgar_date_idx ON edgar_map(edgar_timestamp);\n",
      "CREATE INDEX edgar_form_idx ON edgar_map(form_type);"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Build the map for all EDGAR filings. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_edgar_map_file(path='/edgar/full-index/2003/QTR4/', filename = 'master.gz', to_db=True):\n",
      "    '''\n",
      "    this function conencts to edgar ftp and retrieves a map file\n",
      "    it loads the file into a pd.DataFrame and checks against the DB to remove any records previously processed. \n",
      "    '''\n",
      "    \n",
      "    # \n",
      "    ## get the file from FTP and close connection. \n",
      "    #\n",
      "    ftp = edgar_connect()\n",
      "    ftp.retrbinary(\"RETR \"+path+filename, open(filename, 'wb').write)\n",
      "    ftp.quit()\n",
      "    #\n",
      "    ## read the file into a DF\n",
      "    #\n",
      "    ed= pd.read_table(filename, compression='gzip', header=1, skiprows=[0,1,2,3,4,5,6,9], sep='|')\n",
      "    #\n",
      "    # change the column names on the dataframe. \n",
      "    ed.columns = [\"cik name form_type date filename\".split()]\n",
      "    #\n",
      "    # and change the order of the columns\n",
      "    ed = ed[\"date cik form_type name filename\".split()]\n",
      "    #\n",
      "    return ed\n",
      "\n",
      "        \n",
      "def add_cpy_id_to_ed(ed):\n",
      "    '''\n",
      "    this function gets the cik to link with the edgar_files\n",
      "    '''\n",
      "    cik_cpy = nc.read_db('SELECT tic_ticker, ticker FROM ticker WHERE ticker.src_id=11;')\n",
      "    #for row in ed.values:\n",
      "        \n",
      "        \n",
      "ed = get_edgar_map_file (to_db=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cik_cpy = nc.read_db('SELECT tic_ticker, cpy_id FROM ticker WHERE ticker.src_id=11;')\n",
      "cik_cpy.columns = [\"cik\", \"cpy_id\"]\n",
      "cik_cpy.index = cik_cpy.cik\n",
      "#print ed.merge(cik_cpy, how='inner', on=\"cik\")\n",
      "\n",
      "for i in range(10):\n",
      "    print ed.iloc[i:i+1]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "         date      cik form_type            name  \\\n",
        "0  2003-10-31  1000015    10-K/A  META GROUP INC   \n",
        "\n",
        "                                      filename  \n",
        "0  edgar/data/1000015/0001047469-03-035439.txt  \n",
        "         date      cik form_type            name  \\\n",
        "1  2003-11-14  1000015      10-Q  META GROUP INC   \n",
        "\n",
        "                                      filename  \n",
        "1  edgar/data/1000015/0001104659-03-026504.txt  \n",
        "         date      cik form_type            name  \\\n",
        "2  2003-11-04  1000015         4  META GROUP INC   \n",
        "\n",
        "                                      filename  \n",
        "2  edgar/data/1000015/0001259692-03-000016.txt  \n",
        "         date      cik form_type            name  \\\n",
        "3  2003-11-26  1000015         4  META GROUP INC   \n",
        "\n",
        "                                      filename  \n",
        "3  edgar/data/1000015/0001259692-03-000019.txt  \n",
        "         date      cik form_type            name  \\\n",
        "4  2003-11-26  1000015         4  META GROUP INC   \n",
        "\n",
        "                                      filename  \n",
        "4  edgar/data/1000015/0001259692-03-000020.txt  \n",
        "         date      cik form_type            name  \\\n",
        "5  2003-12-01  1000015         4  META GROUP INC   \n",
        "\n",
        "                                      filename  \n",
        "5  edgar/data/1000015/0001259692-03-000022.txt  \n",
        "         date      cik form_type            name  \\\n",
        "6  2003-12-02  1000015         4  META GROUP INC   \n",
        "\n",
        "                                      filename  \n",
        "6  edgar/data/1000015/0001259692-03-000024.txt  \n",
        "         date      cik form_type            name  \\\n",
        "7  2003-12-03  1000015         4  META GROUP INC   \n",
        "\n",
        "                                      filename  \n",
        "7  edgar/data/1000015/0001259692-03-000026.txt  \n",
        "         date      cik form_type            name  \\\n",
        "8  2003-12-04  1000015         4  META GROUP INC   \n",
        "\n",
        "                                      filename  \n",
        "8  edgar/data/1000015/0001259692-03-000028.txt  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         date      cik form_type            name  \\\n",
        "9  2003-12-08  1000015         4  META GROUP INC   \n",
        "\n",
        "                                      filename  \n",
        "9  edgar/data/1000015/0001259692-03-000030.txt  \n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### IMPORTS\n",
      "from ftplib import FTP\n",
      "import re\n",
      "import urllib2\n",
      "from datetime import datetime\n",
      "import pandas as pd\n",
      "import gzip\n",
      "from glob import glob\n",
      "from lxml import etree, html\n",
      "from lxml.html.clean import clean_html\n",
      "import urllib2\n",
      "import nucleus as nc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## FUNCTION TO CONNECT TO THE FTP\n",
      "\n",
      "\n",
      "def edgar_connect():\n",
      "    ' This is a generic function to establish a connection with the edgar FTP '\n",
      "    ftp = FTP('ftp.sec.gov')\n",
      "    ftp.login(user='anonymous', passwd='pablo@fractalsoft.biz')\n",
      "    # get to the folder containing all the indexes. \n",
      "    return ftp\n",
      "\n",
      "\n",
      "\n",
      "## FUNCTION THAT GETS THE MAP FILE\n",
      "\n",
      "\n",
      "def get_edgar_map_file(path='/edgar/full-index/2003/QTR4/', filename = 'master.gz', to_db=True):\n",
      "    '''\n",
      "    this function conencts to edgar ftp and retrieves a map file\n",
      "    it loads the file into a pd.DataFrame and checks against the DB to remove any records previously processed. \n",
      "    '''\n",
      "    try:\n",
      "        # \n",
      "        ## get the file from FTP and close connection. \n",
      "        #\n",
      "        ftp = edgar_connect()\n",
      "        ftp.retrbinary(\"RETR \"+path+filename, open(filename, 'wb').write)\n",
      "        ftp.quit()\n",
      "        #\n",
      "        ## read the file into a DF\n",
      "        #\n",
      "        ed= pd.read_table(filename, compression='gzip', header=1, skiprows=[0,1,2,3,4,5,6,9], sep='|')\n",
      "        #\n",
      "        # change the column names on the dataframe. \n",
      "        ed.columns = [\"cik name form_type date filename\".split()]\n",
      "        #\n",
      "        # and change the order of the columns\n",
      "        ed = ed[\"date cik form_type name filename\".split()]\n",
      "        #\n",
      "        ed = add_cpy_id_to_ed(ed)\n",
      "        #\n",
      "        ## get the last record from db. \n",
      "        last_db_record = nc.read_db('SELECT edgar_filename FROM edgar_map order by edgar_id desc limit 1;').values[0][0]\n",
      "        #\n",
      "        ## If the last record on DB is duplicate, eliminate all prev records: \n",
      "        if last_db_record in ed.filename.values[-1]:\n",
      "            # if the last record is also the last entry on ed. \n",
      "            return \n",
      "        elif last_db_record in ed.filename.values: \n",
      "            ed = ed[ed[ed.filename == last_db_record].index:]\n",
      "        # write the DF on DB\n",
      "        if to_db: \n",
      "            write_ed(ed)\n",
      "        else: \n",
      "            return ed\n",
      "    except Exception as e:\n",
      "        print e\n",
      "\n",
      "\n",
      "        \n",
      "        \n",
      "### FUNCTIONS THAT WRITE THE FILE TO DB IN PARALLEL. \n",
      "def write_ed(ed): \n",
      "    '''\n",
      "    this function generates and calls the parallel function to write into DB. \n",
      "    '''\n",
      "    cpu = nc.cpu_count()\n",
      "    ed_task = [(write_ed_par, (ed, idx, cpu)) for idx in range(cpu)]\n",
      "    nc.multi_process(ed_task)\n",
      "    return \n",
      "\n",
      "def write_ed_par(ed, idx=0, cpu=1): \n",
      "    '''\n",
      "    ed if a dataframe containing entries of the map for the edgar site\n",
      "    '''\n",
      "    sql = str(\"INSERT INTO edgar_map(edgar_timestamp, cpy_id, \"+\n",
      "              \"form_type, edgar_filename) \"+\n",
      "              \"VALUES(%s, %s, %s, %s);\")\n",
      "    \n",
      "    data = []\n",
      "    #\n",
      "    # split the file in 1 shot\n",
      "    #\n",
      "    data = []\n",
      "    split = len(ed)/cpu\n",
      "    if idx >= cpu-1:\n",
      "        data_file = ed[idx*split:]\n",
      "    else: \n",
      "        data_file = ed[idx*split : (1+idx)*split]\n",
      "    for row in data_file.values: \n",
      "        data += [tuple(row)]\n",
      "    nc.write_db(sql, data)\n",
      "    return  \n",
      "\n",
      "\n",
      "\n",
      "###  FUNCTION THAT GENERATE THE PATH AN FILENAME TO DOWNLOAD THE MAP FOR A FULL DAY OR QUATER\n",
      "\n",
      "def get_edgar_days(last_day, today): \n",
      "    path = '/edgar/daily-index/'\n",
      "    # get the list of idx files. \n",
      "    ftp = edgar_connect()\n",
      "    ftp.cwd(path)\n",
      "    filenames= re.findall('master.[0-9]*.idx', str(ftp.nlst()))\n",
      "    ftp.quit()\n",
      "    #\n",
      "    # Extract the valid dates from the list\n",
      "    file_dates = re.findall('[0-9][0-9]*', str(filenames))\n",
      "    # now get the dates that are present in the filesnames\n",
      "    #\n",
      "    # generate a pandas time range covering all the necessary days\n",
      "    date_range =  pd.date_range(last_day, periods=(today-last_day).days, freq='d')\n",
      "    #\n",
      "    # Loop over the generated dates, and find the ones that are missing. \n",
      "    for i in range(1, len(date_range)):\n",
      "        target_date = date_range[i].strftime(\"%Y%d%m\")\n",
      "        if target_date in file_dates:\n",
      "            get_edgar_map_file(path, filenames[file_dates.index(target_date)])\n",
      "               \n",
      "    \n",
      "    return\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def get_edgar_quaters(last_day):\n",
      "    '''\n",
      "    this function gets the edgar_map, 1 quater at a time\n",
      "    '''\n",
      "    ftp = edgar_connect()\n",
      "    ftp.cwd('/edgar/full-index')\n",
      "    # get a list of the years available for download\n",
      "    years = re.findall('[0-9][0-9][0-9][0-9]', str(ftp.nlst()))\n",
      "    ftp.quit()\n",
      "    \n",
      "    for year in years:\n",
      "        # For the last year already in DB. get only the quaters that are missing. \n",
      "        if int(year) == last_day.year:\n",
      "            ftp = edgar_connect()\n",
      "            ftp.cwd('/edgar/full-index/%s/' %(year))\n",
      "            quater_list = re.findall('QTR[0-9]', str(ftp.nlst()))\n",
      "            ftp.quit()\n",
      "            for quater in quater_list[(last_day.month/3):]: \n",
      "                path = \"/edgar/full-index/%s/%s/\"%(year, quater)\n",
      "                get_edgar_map_file(path, 'master.gz')\n",
      "        # for every other year, get all quaters. \n",
      "        elif int(year) > last_day.year:\n",
      "            ftp = edgar_connect()\n",
      "            ftp.cwd('/edgar/full-index/%s/' %(year))\n",
      "            # get a list of the quaters available for download. \n",
      "            quater_list = re.findall('QTR[0-9]', str(ftp.nlst()))\n",
      "            ftp.quit()\n",
      "            for quater in quater_list: \n",
      "                path = \"/edgar/full-index/%s/%s/\"%(year, quater)\n",
      "                get_edgar_map_file(path, 'master.gz')\n",
      "        else: \n",
      "            print year+\" already in database\"\n",
      "    return\n",
      "#\n",
      "\n",
      "\n",
      "### FUNCTION THAT CHECKS THE LAST DAY ON FILE AND CHOOSES TO DOWNLOAD QUATERS OR DAYS\n",
      "\n",
      "\n",
      "def build_edgar_masters(truncate=False):\n",
      "    '''\n",
      "    This program crawls through the SEC FTP site and gets all the historic master files. \n",
      "    It first reads from the DB to get the last date on record. \n",
      "    \n",
      "    '''\n",
      "    if truncate: nc.truncate_db('edgar_map')\n",
      "    \n",
      "    # check the date of the last masters record in db. \n",
      "    last_day = pd.tslib.Timestamp(nc.read_db(\"SELECT MAX(edgar_timestamp) FROM edgar_map; \").values[0][0])\n",
      "    #\n",
      "    today = pd.Timestamp('today')\n",
      "    #\n",
      "    if (today-last_day).days >=30: \n",
      "        get_edgar_quaters(last_day)\n",
      "    else: \n",
      "        # if less than 30 days are missing\n",
      "        get_edgar_days(last_day, today)\n",
      "    #\n",
      "    return\n",
      "\n",
      "\n",
      "#build_edgar_masters()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "this function adds all CIK to the DB.  :) \n",
      "\n",
      "map the company id to a CIK using yahoo to find the CIK number. \n",
      "src_id = 11 # sec\n",
      "exg_id\n",
      "\n",
      "\n",
      "this query gets all the stocks based in NY: \n",
      "    \n",
      "    SELECT DISTINCT exchange.exg_name, exchange.exg_id \n",
      "    FROM exchange JOIN ticker using (exg_id)\n",
      "    WHERE exchange.loc_id = 150; \n",
      "    \n",
      "           exg_name            | exg_id \n",
      "-------------------------------+--------\n",
      " NASDAQ - ALL MARKETS          |    534\n",
      " NEW YORK STOCK EXCHANGE, INC. |    536\n",
      "\n",
      "\n",
      "# this sql query gets all the NY symbols. \n",
      "    SELECT DISTINCT ticker.tic_ticker\n",
      "    FROM ((ticker JOIN source USING (src_id)) JOIN exchange USING (exg_id))\n",
      "    WHERE source.src_abbr = 'yaho' AND exchange.loc_id = 150;\n",
      "\n",
      "'''\n",
      "def get_cik(ticker):\n",
      "    '''\n",
      "    this function uses yahoo to translate a ticker into a CIK\n",
      "    '''\n",
      "    url = \"http://finance.yahoo.com/q/sec?s=%s+SEC+Filings\"%(ticker)\n",
      "    return int(re.findall('=[0-9]*', str(re.findall('cik=[0-9]*', urllib2.urlopen(url).read())[0]))[0][1:])\n",
      "\n",
      "\n",
      "\n",
      "def map_cik_to_cpy():\n",
      "    '''\n",
      "    this function writes the CIK codes into DB using yahoo to translate them. \n",
      "        data to insert into the db\n",
      "        tick_ticker -> get_cik(ticker[0])\n",
      "        cpy_id -> ticker[1]\n",
      "        src_id = 11 -> SEC\n",
      "        exg_id = ticker[2]\n",
      "    '''\n",
      "    # the ticker list applies 2 filters. 1st: it gets only US listed stocks, and it gets only tickers for which we have\n",
      "    # no CIK already in the DB. \n",
      "    ticker_list = nc.read_db('SELECT ticker.tic_ticker, ticker.cpy_id, exg_id '+\n",
      "                             'FROM ((ticker JOIN source USING (src_id)) JOIN exchange USING (exg_id)) '+\n",
      "                             \"WHERE source.src_abbr = 'yaho' AND exchange.loc_id = 150 \"+\n",
      "                             \"AND ticker.cpy_id NOT IN \"\n",
      "                             \"(SELECT ticker.cpy_id FROM ticker WHERE ticker.src_id=11);\")\n",
      "    cpu = nc.cpu_count()\n",
      "    cik_task = [(map_cik_par, (ticker_list, idx, cpu)) for idx in range(cpu)]\n",
      "    nc.multi_process(cik_task, has_output=False)\n",
      "    return\n",
      "    \n",
      "def map_cik_par(ticker_list, idx=0, cpu=1):\n",
      "    split = len(ticker_list)/cpu\n",
      "    sql = \"INSERT INTO ticker(tic_ticker, cpy_id, src_id, exg_id) VALUES ( %s, %s, %s, %s);\"\n",
      "    if idx == 0 :\n",
      "        print \"processing %s items per cpu\"%(split)\n",
      "    # split the data for each cpu core   \n",
      "    if idx >= cpu-1:\n",
      "        data_file = ticker_list[idx*split:]\n",
      "    else: \n",
      "        data_file = ticker_list[idx*split : (1+idx)*split]   \n",
      "    data = []\n",
      "    j=0\n",
      "    for row in data_file.values: \n",
      "        try: \n",
      "            data += [tuple([get_cik(row[0]),row[1],11, row[2]])] \n",
      "        except: \n",
      "            print row\n",
      "        j +=1\n",
      "        if j % 100 == 1:\n",
      "            nc.write_db(sql, data) # write 100 records to db\n",
      "            data = [] # reset data\n",
      "            if idx == 0:\n",
      "                print \"%s of %s downloaded\"%(j, split)\n",
      "                print \"#######   writting db   #######\"\n",
      "    \n",
      "    \n",
      "    \n",
      "    return \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "map_cik_to_cpy()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Functions to get the Filings\n",
      "\n",
      "These functions will use the edgar_map to get the files related to a given stock. \n",
      "\n",
      "\n",
      "target -> get all the 8k filings for a given stock. \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "SIC code can be used to see the stocks classified into a particular industry by the SEC... \n",
      "\n",
      "http://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&SIC=2911&owner=exclude&match=&start=0&count=100&hidefilings=0\n",
      "\n",
      "\n",
      "\n",
      "## Alternative to get get details. \n",
      "We are going to use the front end of the EDGAR site to find the item #'s for all the filings \n",
      "\n",
      "we'll extract information on xml format, then check against the db to make sure to have all of the items we need. \n",
      "\n",
      "once we have all the items we will parse the html files knowing in advanced which items to look for :) \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## New work flow... using the ATOM feed. \n",
      "\n",
      "1. user requests ticker\n",
      "2. get cik from yahoo  \n",
      "    a. add to DB. \n",
      "3. get atom feed for cik\n",
      "4. get accession number for all entries\n",
      "    a. use the accession number to map them back to the edgar_map db. \n",
      "    \n",
      "5. add item values to DB. \n",
      "    a. we need a DB structure to store the filings data. \n",
      "\n",
      "\n",
      "filings table: \n",
      "\n",
      "    CREATE TABLE IF NOT EXISTS edgar_filings\n",
      "    (\n",
      "    \n",
      "    );\n",
      "\n",
      "\n",
      "extra steps\n",
      "\n",
      "1. add cik to db\n",
      "2. add industry code and description to db\n",
      "    a. add source to industry codes    <<-- this will help when we apply AI to the SEC data\n",
      "3. \n",
      "\n",
      "\n",
      "\n",
      "## use case: \n",
      "#### Display industry chart\n",
      "\n",
      "1. user enters stock ticker\n",
      "2. system gets cik from yahoo\n",
      "3. system gets atom feed for cik\n",
      "4. system gets industry stocks for cik\n",
      "5. system creates Quoteboard file with all industry stocks\n",
      "6. system gets long term data for all industry stocks from yahoo? \n",
      "7. system displays chart\n",
      "\n",
      "#### display 8k filings\n",
      "\n",
      "1. user enters stock ticker\n",
      "2. system gets cik from yahoo\n",
      "3. system gets atom feed for cik\n",
      "4. system gets all entries from the atom feed\n",
      "5. system gets filings from edgar-ftp\n",
      "6. system displays item types\n",
      "7. user filters item-types to display  - Item: description\n",
      "8. system displays all items in text format. \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "details = html_cleaner( 'filing.html')\n",
      "print details.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['item 2.02', 'item 7.01', 'item 1']\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "form_8k = read_edgar_map(ticker=\"XOM\", form_type=\"8-K\")\n",
      "print form_8k.head()\n",
      "\n",
      "\n",
      "forms = pd.DataFrame()\n",
      "for i in range(len(form_8k)): # << -- we can use this loop to paralellize... \n",
      "    # get 1 filing. \n",
      "    item = form_8k.iloc[i:i+1]\n",
      "    print item\n",
      "    get_filing(item.edgar_filename)\n",
      "    details = html_cleaner( 'filing.txt', verbose)\n",
      "    print details\n",
      "    break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'read_edgar_map' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-50-6a96afbe94df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"edgar/data/34088/0000034088-13-000043.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mform_8k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_edgar_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"XOM\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mform_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"8-K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mform_8k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'read_edgar_map' is not defined"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print details.keys()\n",
      "print details['item 2.02']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['item 2.02', 'item 7.01', 'item 1']\n",
        "\n",
        "  Item 2.02\n",
        "  \n",
        " \n",
        "  Results of Operations and\n",
        "  Financial Condition\n",
        "  \n",
        " \n",
        "\n",
        "  \n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_edgar_map_file(path='/edgar/full-index/2003/QTR4/', filename = 'master.gz', to_db=True):\n",
      "    '''\n",
      "    this function conencts to edgar ftp and retrieves a map file\n",
      "    it loads the file into a pd.DataFrame and checks against the DB to remove any records previously processed. \n",
      "    '''\n",
      "    try:\n",
      "        # \n",
      "        ## get the file from FTP and close connection. \n",
      "        #\n",
      "        ftp = edgar_connect()\n",
      "        ftp.retrbinary(\"RETR \"+path+filename, open(filename, 'wb').write)\n",
      "        ftp.quit()\n",
      "        #\n",
      "        ## read the file into a DF\n",
      "        #\n",
      "        ed= pd.read_table(filename, compression='gzip', header=1, skiprows=[0,1,2,3,4,5,6,9], sep='|')\n",
      "        #\n",
      "        # change the column names on the dataframe. \n",
      "        ed.columns = [\"cik name form_type date filename\".split()]\n",
      "        #\n",
      "        # and change the order of the columns\n",
      "        ed = ed[\"date cik form_type name filename\".split()]\n",
      "        #\n",
      "        ## get the last record from db. \n",
      "        last_db_record = nc.read_db('SELECT edgar_filename FROM edgar_map order by edgar_id desc limit 1;').values[0][0]\n",
      "        #\n",
      "        ## If the last record on DB is duplicate, eliminate all prev records: \n",
      "        if last_db_record in ed.filename.values[-1]:\n",
      "            # if the last record is also the last entry on ed. \n",
      "            return \n",
      "        elif last_db_record in ed.filename.values: \n",
      "            ed = ed[ed[ed.filename == last_db_record].index:]\n",
      "        # write the DF on DB\n",
      "        if to_db: \n",
      "            write_ed(ed)\n",
      "        else: \n",
      "            return ed\n",
      "    except Exception as e:\n",
      "        print e"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "XOM.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>edgar_id</th>\n",
        "      <th>edgar_timestamp</th>\n",
        "      <th>edgar_cik</th>\n",
        "      <th>form_type</th>\n",
        "      <th>edgar_name</th>\n",
        "      <th>edgar_filename</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 13770329</td>\n",
        "      <td>2013-10-31 00:00:00</td>\n",
        "      <td> 34088</td>\n",
        "      <td> 8-K</td>\n",
        "      <td> EXXON MOBIL CORP</td>\n",
        "      <td> edgar/data/34088/0000034088-13-000043.txt</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 12752628</td>\n",
        "      <td>2012-12-04 00:00:00</td>\n",
        "      <td> 34088</td>\n",
        "      <td> 8-K</td>\n",
        "      <td> EXXON MOBIL CORP</td>\n",
        "      <td> edgar/data/34088/0000034088-12-000054.txt</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 12752626</td>\n",
        "      <td>2012-11-30 00:00:00</td>\n",
        "      <td> 34088</td>\n",
        "      <td> 8-K</td>\n",
        "      <td> EXXON MOBIL CORP</td>\n",
        "      <td> edgar/data/34088/0000034088-12-000052.txt</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 12752624</td>\n",
        "      <td>2012-11-02 00:00:00</td>\n",
        "      <td> 34088</td>\n",
        "      <td> 8-K</td>\n",
        "      <td> EXXON MOBIL CORP</td>\n",
        "      <td> edgar/data/34088/0000034088-12-000048.txt</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 12752622</td>\n",
        "      <td>2012-11-01 00:00:00</td>\n",
        "      <td> 34088</td>\n",
        "      <td> 8-K</td>\n",
        "      <td> EXXON MOBIL CORP</td>\n",
        "      <td> edgar/data/34088/0000034088-12-000044.txt</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "   edgar_id     edgar_timestamp  edgar_cik form_type        edgar_name  \\\n",
        "0  13770329 2013-10-31 00:00:00      34088       8-K  EXXON MOBIL CORP   \n",
        "1  12752628 2012-12-04 00:00:00      34088       8-K  EXXON MOBIL CORP   \n",
        "2  12752626 2012-11-30 00:00:00      34088       8-K  EXXON MOBIL CORP   \n",
        "3  12752624 2012-11-02 00:00:00      34088       8-K  EXXON MOBIL CORP   \n",
        "4  12752622 2012-11-01 00:00:00      34088       8-K  EXXON MOBIL CORP   \n",
        "\n",
        "                              edgar_filename  \n",
        "0  edgar/data/34088/0000034088-13-000043.txt  \n",
        "1  edgar/data/34088/0000034088-12-000054.txt  \n",
        "2  edgar/data/34088/0000034088-12-000052.txt  \n",
        "3  edgar/data/34088/0000034088-12-000048.txt  \n",
        "4  edgar/data/34088/0000034088-12-000044.txt  "
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## These functions get the files that match entries on the map. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def edgar_get(ticker=None, start_day=None, end_day=None, item=None, form_type=None):\n",
      "    '''\n",
      "    this tool processes user requests for edgar data. \n",
      "    '''\n",
      "    ed_map = read_edgar_map(ticker, start_day, end_day, form_type)  \n",
      "    # get 8k fillings\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "##### DEFINE SOME VARIABLES\n",
      "\n",
      "path = '/edgar/daily-index/'\n",
      "today = pd.Timestamp('today')\n",
      "#last_day = nc.read_db(\"SELECT MAX(edgar_timestamp) FROM edgar_map; \") \n",
      "last_day = pd.tslib.Timestamp(nc.read_db(\"SELECT MAX(edgar_timestamp) FROM edgar_map; \").values[0][0])\n",
      "####  GET FTP DATA\n",
      "\n",
      "ftp = edgar_connect()\n",
      "ftp.cwd(path)\n",
      "filenames= re.findall('master.[0-9]*.idx', str(ftp.nlst()))\n",
      "ftp.quit()\n",
      "\n",
      "## use REGEX to extract the dates. \n",
      "\n",
      "file_dates = re.findall('[0-9][0-9]*', str(filenames))\n",
      "\n",
      "\n",
      "## BUILD TEH DATE RANGE\n",
      "\n",
      "date_range =  pd.date_range(last_day, periods=(today-last_day).days, freq='d')\n",
      "for i in range(1, len(date_range)):\n",
      "    target_date = date_range[i].strftime(\"%Y%d%m\")\n",
      "    if target_date in file_dates:\n",
      "        get_edgar_map_file(path, filenames[file_dates.index(target_date)])\n",
      "\n",
      "\n",
      "    \n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}